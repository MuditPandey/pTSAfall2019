{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS-GA 3001.009 Modeling Time Series Data\n",
    "\n",
    "# Week 5 Hidden Markov Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import pylab\n",
    "from collections import Counter\n",
    "from hmmlearn import hmm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I Data Loading\n",
    "\n",
    "Load the Wall Street Journal POS dataset. Transform them into indices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dir = \"../../data/en-wsj-train.pos\"\n",
    "test_dir = \"../../data/en-wsj-dev.pos\"\n",
    "\n",
    "def load_pos_data(data_dir, word_indexer=None, label_indexer=None, top_k=20000):\n",
    "    \"\"\"\n",
    "    Function that loads the data\n",
    "    \"\"\"\n",
    "    with open(data_dir, \"r\") as f:\n",
    "        # load data\n",
    "        content = f.readlines()\n",
    "        intermediate_X = []\n",
    "        intermediate_y = []\n",
    "        current_X = []\n",
    "        current_y = []\n",
    "        vocab_counter = Counter()\n",
    "        label_set = set()\n",
    "        for line in content:\n",
    "            tokens = line.replace(\"\\n\", \"\").replace(\"$\", \"\").split(\"\\t\")\n",
    "            if len(tokens) <= 1:\n",
    "                intermediate_X.append(current_X)\n",
    "                intermediate_y.append(current_y)\n",
    "                current_X = []\n",
    "                current_y = []\n",
    "            elif len(tokens[1]) > 0:\n",
    "                vocab_counter[tokens[0]]+=1\n",
    "                label_set.add(tokens[1])\n",
    "                current_X.append(tokens[0].lower())\n",
    "                current_y.append(tokens[1])\n",
    "        # index data\n",
    "        top_k_words = vocab_counter.most_common(top_k)\n",
    "        # 0 is reserved for unknown words\n",
    "        word_indexer = word_indexer if word_indexer is not None else dict([(top_k_words[i][0], i+1) for i in range(len(top_k_words))])\n",
    "        word_indexer[\"UNK\"] = 0 \n",
    "        label_indexer = label_indexer if label_indexer is not None else dict([(label, i) for i, label in enumerate(label_set)])\n",
    "        output_X = []\n",
    "        output_y = []\n",
    "        current_X = []\n",
    "        current_y = []\n",
    "        for i in range(len(intermediate_X)):\n",
    "            for j in range(len(intermediate_X[i])):\n",
    "                if intermediate_X[i][j] in word_indexer:\n",
    "                    current_X.append(word_indexer[intermediate_X[i][j]])\n",
    "                else:\n",
    "                    current_X.append(0)\n",
    "                current_y.append(label_indexer[intermediate_y[i][j]])\n",
    "            # populate holders\n",
    "            output_X.append(current_X)\n",
    "            output_y.append(current_y)\n",
    "            # reset current holder\n",
    "            current_X = []\n",
    "            current_y = []\n",
    "        return output_X, output_y, label_indexer, word_indexer, {v: k for k, v in label_indexer.items()}, {v: k for k, v in word_indexer.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X, train_y, label_indexer, word_indexer, label_lookup, vocab_lookup = load_pos_data(train_dir)\n",
    "test_X, test_y, _, _, _, _ = load_pos_data(test_dir, word_indexer=word_indexer, label_indexer=label_indexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1700"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X)\n",
    "len(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II HMM Implementation\n",
    "\n",
    "In this part, you will implement the Hidden Markov Model with following methods:\n",
    "\n",
    "\n",
    "- sample: given a initial state and the number of steps, returns a sequence of sampled states and observations.\n",
    "\n",
    "\n",
    "- fit: update the transition matrix, emission matrix, and the initial state probability. Note that in our case, the hidden states are given. We don't need to use EM for the learning.\n",
    "\n",
    "\n",
    "- decode_single_chain: use the Viterbi Algorithm to find the most probable sequence of states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reconstruct_sequence(idx_list, lookup):\n",
    "    \"\"\"\n",
    "    Function that reconstructs a sequence of index\n",
    "    \"\"\"\n",
    "    return [lookup[x] for x in idx_list]\n",
    "\n",
    "def percentage_agree(x, y):\n",
    "    \"\"\"\n",
    "    Function that shows the % of agreement among two list\n",
    "    \"\"\"\n",
    "    assert len(x)==len(y)\n",
    "    return float(np.sum(np.array(x)==np.array(y)))/len(x)\n",
    "\n",
    "class MyHMM:\n",
    "    def __init__(self, num_unique_states, num_observations):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        @param num_unique_states: # of unique states (POS Tags)\n",
    "        @param num_observations: # of unique observations (words)\n",
    "        \"\"\"\n",
    "        self.num_unique_states = num_unique_states\n",
    "        self.num_observations = num_observations\n",
    "        self.transition_matrix = np.zeros((num_unique_states, num_unique_states))\n",
    "        self.emission_matrix = np.zeros((num_unique_states, num_observations))\n",
    "        self.initial_states_vector = np.zeros(num_unique_states)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Method that fits the model.\n",
    "        @param X: array-like with dimension [# of examples, # of length]\n",
    "        @param y: array-like with dimension [# of examples, # of length]\n",
    "        \"\"\"\n",
    "        # populate holders\n",
    "        for i in range(len(y)):\n",
    "            for j in range(len(y[i])):\n",
    "                # update initial state probability\n",
    "                if j == 0:\n",
    "                    self.initial_states_vector[y[i][j]] += 1\n",
    "                # update transition matrix\n",
    "                if j < len(y[i])-1:\n",
    "                    self.transition_matrix[y[i][j], y[i][j+1]] += 1\n",
    "                # update emission matrix\n",
    "                self.emission_matrix[y[i][j], X[i][j]] += 1\n",
    "        # normalization\n",
    "        self.initial_states_vector += 1e-10\n",
    "        self.initial_states_vector /= np.sum(self.initial_states_vector)\n",
    "        \n",
    "        self.transition_matrix += 1e-10\n",
    "        row_sums_transition_matrix = np.sum(self.transition_matrix, axis=1)\n",
    "        self.transition_matrix /= row_sums_transition_matrix[:, np.newaxis]\n",
    "        \n",
    "        self.emission_matrix += 1e-10\n",
    "        row_sums_emission_matrix = np.sum(self.emission_matrix, axis=1)\n",
    "        self.emission_matrix /= row_sums_emission_matrix[:, np.newaxis]\n",
    "    \n",
    "    def decode_single_chain(self, x):\n",
    "        \"\"\"\n",
    "        Auxiliary method that uses Viterbi on single chain\n",
    "        @param X: array-like with dimension [ # of length]\n",
    "        @return y: array-like with dimension [# of length]\n",
    "        \"\"\"\n",
    "        # init holders\n",
    "        y = []\n",
    "        V = np.zeros( (len(x), self.num_unique_states) )\n",
    "        best_states = np.zeros( (len(x), self.num_unique_states) )\n",
    "        # populate the dynamic matrix\n",
    "        for t in range(len(x)):\n",
    "            for j in range(self.num_unique_states):\n",
    "                # v[t,j] = max_{i} v[t-1, i] * transition_matrix[i,j] * emission_matrix[j, x_t]\n",
    "                if t == 0:\n",
    "                    prev_V = np.log(self.initial_states_vector)\n",
    "                else:\n",
    "                    prev_V = V[t-1, :]\n",
    "                candidate_list = prev_V + np.log(self.transition_matrix[:,j]) + np.log(self.emission_matrix[j, x[t]])\n",
    "                best_i = np.argmax(candidate_list)\n",
    "                \n",
    "                # populate holders\n",
    "                V[t,j] = candidate_list[best_i]\n",
    "                best_states[t,j] = int(best_i)\n",
    "        # trace back: from T-1 to 1 (zero-indexed), don't need to look at t=0, meaning less        \n",
    "        for t in range(len(x), 0, -1):\n",
    "            if t == len(x):\n",
    "                current_j = int(np.argmax(V[t-1, :]))\n",
    "                y.append(current_j)\n",
    "            else:\n",
    "                current_j = int(best_states[t, current_j])\n",
    "                y.append(current_j)\n",
    "        # reverse y\n",
    "        return list(reversed(y))\n",
    "        \n",
    "    def decode(self, X):\n",
    "        \"\"\"\n",
    "        Method that performs the Viterbi the model.\n",
    "        @param X: array-like with dimension [# of examples, # of length]\n",
    "        @return y: array-like with dimension [# of examples, # of length]\n",
    "        \"\"\"\n",
    "        return [self.decode_single_chain(sample) for sample in X]\n",
    "    \n",
    "    def sample(self, n_step, initial_state):\n",
    "        \"\"\"\n",
    "        Method that given initial state and produces n_step states and observations\n",
    "        @param n_step: integer\n",
    "        @param initial_state: an integer indicating the state\n",
    "        \"\"\"\n",
    "        states = []\n",
    "        observations = []\n",
    "        curent_state = initial_state\n",
    "        for t in range(n_step):\n",
    "            transition_prob = self.transition_matrix[curent_state, :]\n",
    "            curent_state = np.random.choice(list(range(self.num_unique_states)), p=transition_prob)\n",
    "            emission_prob = self.emission_matrix[curent_state, :]\n",
    "            observation = np.random.choice(list(range(self.num_observations)), p=emission_prob)\n",
    "            states.append(curent_state)\n",
    "            observations.append(observation)\n",
    "        return states, observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn an HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_states = len(label_indexer)\n",
    "num_obs = len(word_indexer)\n",
    "my_hmm = MyHMM(num_states, num_obs)\n",
    "my_hmm.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Viterbi to decode a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: ['this', 'financing', 'system', 'was', 'created', 'in', 'the', 'new', 'law', 'in', 'order', 'to', 'keep', 'the', 'bailout', 'spending', 'from', 'swelling', 'the', 'budget', 'deficit', '.'] \n",
      " pred: ['DT', 'NN', 'NN', 'VBD', 'VBN', 'IN', 'DT', 'JJ', 'NN', 'IN', 'NN', 'TO', 'VB', 'DT', 'NN', 'NN', 'IN', 'VBG', 'DT', 'NN', 'NN', '.'] \n",
      " label: ['DT', 'NN', 'NN', 'VBD', 'VBN', 'IN', 'DT', 'JJ', 'NN', 'IN', 'NN', 'TO', 'VB', 'DT', 'NN', 'NN', 'IN', 'VBG', 'DT', 'NN', 'NN', '.']\n"
     ]
    }
   ],
   "source": [
    "i = 5\n",
    "res = my_hmm.decode_single_chain(test_X[i])\n",
    "print(\"data: {0} \\n pred: {1} \\n label: {2}\".format(reconstruct_sequence(test_X[i], vocab_lookup),\n",
    "                                                    reconstruct_sequence(res, label_lookup),\n",
    "                                                  reconstruct_sequence(test_y[i], label_lookup)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "takes 9.493995189666748 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "pred_train = my_hmm.decode(train_X[:1000])\n",
    "print(\"takes {0} seconds\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "takes 15.467236280441284 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "pred_test = my_hmm.decode(test_X)\n",
    "print(\"takes {0} seconds\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93240962302301245"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([percentage_agree(pred_train[i], train_y[i]) for i in range(len(pred_train))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91945955881678232"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([percentage_agree(pred_test[i], test_y[i]) for i in range(len(pred_test))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NNP', 'CC', 'IN', 'CD', 'NNP', 'VBD', 'VBN', '.', \"''\", 'VBZ']\n",
      "['golden', 'and', 'as', '1973', 'UNK', 'rose', 'cut', '.', \"''\", 'UNK']\n"
     ]
    }
   ],
   "source": [
    "pos_tag, words = my_hmm.sample(10, label_indexer[\"NNP\"])\n",
    "print(reconstruct_sequence(pos_tag, label_lookup))\n",
    "print(reconstruct_sequence(words, vocab_lookup))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please turn in the code before 03/01/2018 6:45 pm. Please name your notebook netid.ipynb.\n",
    "\n",
    "### Your work will be evaluated based on the code and plots. You don't need to write down your answers to these questions in the text blocks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Reference\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "for line in sys.stdin:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def haha(my_int):\n",
    "    max_iter = int(np.floor((np.sqrt(my_int))))\n",
    "    factor = []\n",
    "    for i in range(1,max_iter+1):\n",
    "        if my_int % i == 0:\n",
    "            factor.append(i)\n",
    "            if my_int/i != my_int:\n",
    "                factor.append(my_int/i)\n",
    "    return len(set(factor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.03252543e-04,   1.38138892e-03,   3.11440412e-03,\n",
       "         3.51626272e-04,   5.68881075e-02,   7.28368705e-04,\n",
       "         4.16677132e-02,   7.54238352e-02,   2.51161623e-15,\n",
       "         2.03440914e-03,   2.93859098e-03,   2.68742936e-03,\n",
       "         3.76742434e-04,   6.25392440e-03,   8.53949517e-04,\n",
       "         3.01393947e-04,   2.51161623e-15,   5.90229813e-03,\n",
       "         1.22064549e-02,   1.75813136e-04,   2.88835866e-03,\n",
       "         1.63255055e-03,   2.51161623e-15,   2.51161623e-15,\n",
       "         4.21951526e-03,   7.78601030e-04,   1.26108251e-01,\n",
       "         4.01858596e-04,   2.51161623e-05,   2.51161623e-15,\n",
       "         2.00929298e-04,   2.56184855e-03,   5.83699611e-02,\n",
       "         4.12909707e-02,   2.00904182e-01,   6.27904056e-04,\n",
       "         3.61672736e-03,   4.06128344e-02,   2.13487379e-03,\n",
       "         1.45673741e-03,   6.89689815e-02,   1.22818033e-02,\n",
       "         2.16928293e-01,   2.51161623e-15])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_hmm.initial_states_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50%1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sqrt()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
